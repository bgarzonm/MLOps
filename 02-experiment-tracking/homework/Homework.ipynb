{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "The goal of this homework is to get familiar with MLflow, the tool for experiment tracking and \n",
    "model management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Install MLflow\n",
    "\n",
    "To get started with MLflow you'll need to install the MLflow Python package.\n",
    "\n",
    "For this we recommend creating a separate Python environment, for example, you can use [conda environments](https://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html#managing-envs), and then install the package there with `pip` or `conda`.\n",
    "\n",
    "Once you installed the package, run the command `mlflow --version` and check the output.\n",
    "\n",
    "What's the version that you have?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-auth 1.33.0 requires cachetools<5.0,>=2.0.0, but you have cachetools 5.3.3 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow, version 2.13.0\n"
     ]
    }
   ],
   "source": [
    "!mlflow --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Download and preprocess the data\n",
    "\n",
    "We'll use the Green Taxi Trip Records dataset to predict the duration of each trip. \n",
    "\n",
    "Download the data for January, February and March 2023 in parquet format from [here](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page).\n",
    "\n",
    "Use the script `preprocess_data.py` located in the folder [`homework`](homework) to preprocess the data.\n",
    "\n",
    "The script will:\n",
    "\n",
    "* load the data from the folder `<TAXI_DATA_FOLDER>` (the folder where you have downloaded the data),\n",
    "* fit a `DictVectorizer` on the training set (January 2023 data),\n",
    "* save the preprocessed datasets and the `DictVectorizer` to disk.\n",
    "\n",
    "Your task is to download the datasets and then execute this command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/MLOps/02-experiment-tracking/homework/preprocess_data.py\", line 83, in <module>\n",
      "    run_data_prep()\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/click/core.py\", line 1128, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/click/core.py\", line 1053, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/click/core.py\", line 1395, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/click/core.py\", line 754, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"/workspaces/MLOps/02-experiment-tracking/homework/preprocess_data.py\", line 50, in run_data_prep\n",
      "    df_train = read_dataframe(\n",
      "  File \"/workspaces/MLOps/02-experiment-tracking/homework/preprocess_data.py\", line 15, in read_dataframe\n",
      "    df = pd.read_parquet(filename)\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/pandas/io/parquet.py\", line 493, in read_parquet\n",
      "    return impl.read(\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/pandas/io/parquet.py\", line 233, in read\n",
      "    path_or_handle, handles, kwargs[\"filesystem\"] = _get_path_or_handle(\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/pandas/io/parquet.py\", line 102, in _get_path_or_handle\n",
      "    handles = get_handle(\n",
      "  File \"/home/codespace/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 798, in get_handle\n",
      "    handle = open(handle, ioargs.mode)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '../02-experiment-tracking/data/green_tripdata_2023-01.parquet'\n"
     ]
    }
   ],
   "source": [
    "!python preprocess_data.py --raw_data_path  /data/ --dest_path ./output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
